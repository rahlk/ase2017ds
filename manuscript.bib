@INPROCEEDINGS{czer11,
	author =	 {Czerwonka, J. and Das, R. and Nagappan, N. and
	Tarvo, A. and Teterev, A.},
	booktitle =	 {Software Testing, Verification and Validation
	(ICST), 2011 IEEE Fourth International Conference
	on},
	title =	 {CRANE: Failure Prediction, Change Analysis and Test
	Prioritization in Practice -- Experiences from
	Windows},
	year =	 2011,
	month =	 {march},
	pages =	 {357 -366},
}

@inproceedings{ostrand04,
	author =	 {Ostrand, Thomas J. and Weyuker, Elaine J. and Bell,
	Robert M.},
	title =	 {Where the bugs are},
	booktitle =	 {ISSTA '04: Proceedings of the 2004 ACM SIGSOFT
	international symposium on Software testing and
	analysis},
	year =	 2004,
	pages =	 {86--96},
	publisher =	 {ACM},
	address =	 {New York, NY, USA},
}

@article{Menzies2007a,
	abstract = {Zhang and Zhang argue that predictors are useless unless they have high precison{\&}amp;recall. We have a different view, for two reasons. First, for SE data sets with large neg/pos ratios, it is often required to lower precision to achieve higher recall. Second, there are many domains where low precision detectors are useful.},
	author = {Menzies, Tim and Dekhtyar, Alex and Distefano, Justin and Greenwald, Jeremy},
	doi = {10.1109/TSE.2007.70721},
	file = {:C$\backslash$:/Users/Rahul Krishna/Documents/Mendeley Desktop/Menzies et al. - 2007 - Problems with precision A response to Comments on 'data mining static code attributes to learn defect predictors.pdf:pdf},
	issn = {0098-5589},
	journal = {IEEE Transactions on Software Engineering},
	keywords = {Accuracy measures,Defect prediction,Empirical,Static code attributes},
	month = {sep},
	number = {9},
	pages = {637--640},
	title = {{Problems with Precision: A Response to "Comments on 'Data Mining Static Code Attributes to Learn Defect Predictors'"}},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4288197},
	volume = {33},
	year = {2007}
}
@inproceedings{turhan11,
	title={Empirical evaluation of mixed-project defect prediction models},
	author={Turhan, Burak and Tosun, Ay{\c{s}}e and Bener, Ay{\c{s}}e},
	booktitle={Software Engineering and Advanced Applications (SEAA), 2011 37th EUROMICRO Conference on},
	pages={396--403},
	year={2011},
	organization={IEEE}
}

@ARTICLE{koc11b,
	author =	 "E. Kocaguneli and T. Menzies and A. Bener and
	J. Keung",
	journal =	 "IEEE Transactions on Software Engineering",
	title =	 "Exploiting the Essential Assumptions of
	Analogy-Based Effort Estimation",
	year =	 2012,
	volume =	 28,
	issue =	 2,
	pages =	 "425-438",
	note =	 "Available from
	\url{http://menzies.us/pdf/11teak.pdf}",
	class =	 "hJ"
}

@inproceedings{hihn15, 
author={J. Hihn and T. Menzies}, 
booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)}, 
title={Data Mining Methods and Cost Estimation Models: Why is it So Hard to Infuse New Ideas?}, 
year={2015}, 
pages={5-9}, 
keywords={data mining;software cost estimation;NASA;cost estimation models;data mining methods;effort estimation;software costing models;technology infusion;Cognitive science;Data mining;Estimation;NASA;Software;Solid modeling;Stakeholders;cost estimation;data mining;effort estimation;software;technology infusion}, 
doi={10.1109/ASEW.2015.27}, 
month={Nov},}

@article{cortes95,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer Netherlands}
}

@article{lessmann08,
	abstract = {Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general, more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary data sets, relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons, and, finally, limited use of statistical testing procedures to secure empirical findings. To remedy these problems, a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over 10 public domain data sets from the NASA Metrics Data repository. Overall, an appealing degree of predictive accuracy is observed, which supports the view that metric-based classification is useful. However, our results indicate that the importance of the particular classification algorithm may be less than previously assumed since no significant performance differences could be detected among the top 17 classifiers.},
	author = {Lessmann, Stefan and Baesens, Bart and Mues, C. and Pietsch, S.},
	doi = {10.1109/TSE.2008.35},
	isbn = {00985589 (ISSN)},
	issn = {0098-5589},
	journal = {IEEE Trans. Softw. Eng.},
	keywords = {Complexity measures,Data mining,Formal methods,Statistical methods,benchmark testing,benchmarking classification models,code attributes,fault-prone modules,metric-based classification,predictive classification models,proprietary data sets,software defect prediction,software quality,statistical testing,statistical testing procedures,testing efficiency},
	month = {jul},
	number = {4},
	pages = {485--496},
	title = {{Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings}},
	volume = {34},
	year = {2008}
}

@article{dtrees,
  title={Induction of decision trees},
  author={Quinlan, J Ross},
  journal={Machine learning},
  volume={1},
  number={1},
  pages={81--106},
  year={1986},
  publisher={Springer}
}

@article{krishna17a,
	abstract = {Context: Developers use bad code smells to guide code reorganization. Yet developers, text books, tools, and researchers disagree on which bad smells are important. Objective: To evaluate the likelihood that a code reorganization to address bad code smells will yield improvement in the defect-proneness of the code. Method: We introduce XTREE, a tool that analyzes a historical log of defects seen previously in the code and generates a set of useful code changes. Any bad smell that requires changes outside of that set can be deprioritized (since there is no historical evidence that the bad smell causes any problems). Evaluation: We evaluate XTREE's recommendations for bad smell improvement against recommendations from previous work (Shatnawi, Alves, and Borges) using multiple data sets of code metrics and defect counts. Results: Code modules that are changed in response to XTREE's recommendations contain significantly fewer defects than recommendations from previous studies. Further, XTREE endorses changes to very few code metrics, and the bad smell recommendations (learned from previous studies) are not universal to all software projects. Conclusion: Before undertaking a code reorganization based on a bad smell report, use a tool like XTREE to check and ignore any such operations that are useless; i.e. ones which lack evidence in the historical record that it is useful to make that change. Note that this use case applies to both manual code reorganizations proposed by developers as well as those conducted by automatic methods. This recommendation assumes that there is an historical record. If none exists, then the results of this paper could be used as a guide.},
	archivePrefix = {arXiv},
	arxivId = {1609.03614},
	author = {Krishna, Rahul and Menzies, Tim and Layman, Lucas},
	doi = {10.1016/j.infsof.2017.03.012},
	eprint = {1609.03614},
	issn = {09505849},
	journal = {Information and Software Technology},
	keywords = {bad smells,decision trees,performance prediction},
	month = {mar},
	title = {{Less is more: Minimizing code reorganization using XTREE}},
	url = {http://arxiv.org/abs/1609.03614},
	year = {2017}
}
